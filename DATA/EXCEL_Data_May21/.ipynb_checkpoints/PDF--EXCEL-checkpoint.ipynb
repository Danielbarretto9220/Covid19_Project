{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"name":"PDF--EXCEL.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"1AQ-EbFl3wC5"},"source":["Following Code can be used to extract the data from the online pdf and convert it into a excel file. You can get the data by changing the start date"],"id":"1AQ-EbFl3wC5"},{"cell_type":"code","metadata":{"tags":[],"id":"289da777-6d0a-42d1-a801-f5e06663c705","outputId":"780757e8-5e6d-4772-95b2-6d0be607a74d"},"source":["# Comibned Code to extract data from pdf to excel\n","\n","# import necessary packaged \n","import pandas as pd\n","from datetime import date\n","import requests as req\n","import PyPDF2\n","import tabula\n","import numpy as np\n","from openpyxl import Workbook\n","\n","\n","# Date required to enter into the url required to download the pdf\n","now = str(date.today())\n","result = now.split(\"-\")\n","day = pd.to_numeric(result[2])\n","day = day-1\n","result[2] = day.astype(str)\n","today = result[2] + \"/\" + result[1] + \"/\" + result[0]\n","today\n","\n","# An array of dates for traversal\n","date_df = pd.date_range(start='05/01/2021', end=today)\n","\n","\n","# Traverse through the dates to collect data of the respective date\n","for i in date_df:\n","    target_date = i\n","    temp = str(target_date)[:10]\n","    result = temp.split(\"-\")\n","    new_result = date(int(result[0]),int(result[1]),int(result[2]))\n","    month = new_result.strftime(\"%b\").upper()\n","    year = result[0][2:]\n","    # date_requried = the date we'll be working on for each iteration \n","    date_required = result[2] + \"-\" + result[1] + \"-\" + result[0]\n","    print('Working on the following day: ' + date_required)\n","    url = \"https://covid19.karnataka.gov.in/storage/pdf-files/EMB-\"+month+year+\"/\"+date_required+\"%20HMB%20English.pdf\"\n","    \n","    # Read online pdf save offline\n","    response = req.get(url, stream=True)\n","    with open('PDF/'+date_required+'.pdf', 'wb') as pdf:\n","        pdf.write(response.content)\n","    \n","    # Read offline pdf\n","    pdf_path = 'PDF/'+date_required+'.pdf'\n","    pdfReader = PyPDF2.PdfFileReader(pdf_path)\n","    pages = pdfReader.numPages\n","    search_word = \"annexure\"\n","    \n","    # search for the page where we have death reports as this page is different for each pdf\n","    for pageNum in range(0, pages):\n","        pageObj = pdfReader.getPage(pageNum)\n","        text = pageObj.extractText().encode('utf-8')\n","        search_text = text.lower().split()\n","        for word in search_text:\n","            if search_word in word.decode(\"utf-8\"):\n","                 if pageNum >= 40:\n","                        num = pageNum\n","                        \n","    \n","    table = tabula.read_pdf(pdf_path, stream = True, pages = 1, multiple_tables = True, pandas_options={'header': None})\n","    table1 = table[0].iloc[:,1:]\n","                        \n","    strains = tabula.read_pdf(pdf_path, stream = True, pages = 2)\n","    strains = strains[0].dropna().reset_index()\n","    strains = strains.iloc[:,1:]\n","                        \n","    dist_abst = tabula.read_pdf(pdf_path, pages = 5, lattice = True)\n","    dist_abst = dist_abst[0]\n","    dist_abst_temp = dist_abst.iloc[-2:-1,2:]\n","    dist_abst_temp =  dist_abst_temp.dropna(axis='columns')\n","    dist_abst.columns = dist_abst.iloc[1].replace('\\r',' ', regex=True)\n","    dist_abst = dist_abst.iloc[2:33,2:11].set_index('District Name')\n","\n","    deaths = tabula.read_pdf(pdf_path, pages = num+1, area=(85, 20, 820, 570), lattice = True)\n","    deaths = deaths[0]\n","    col_names = deaths.columns\n","    \n","    death_df = pd.DataFrame()\n","    for i in range(num+2,pages+1):\n","        death = tabula.read_pdf(pdf_path, pages = i, area=(10, 20, 820, 800), lattice = True)\n","        death = death[0]\n","        death_df = pd.concat([death_df, death], axis=0)\n","        death_df = death_df.iloc[:,0:11]\n","    death_df.columns = col_names\n","    deaths = pd.concat([deaths, death_df], axis=0)\n","\n","    # Save the data extracted from the pdf to excel\n","    with pd.ExcelWriter('EXCEL/'+date_required+'.xlsx') as writer:  \n","        table1.to_excel(writer, sheet_name='Day_Stats', index=False)\n","        strains.to_excel(writer, sheet_name='Strains', index=False)\n","        dist_abst.to_excel(writer, sheet_name='District', index=False)\n","        deaths.to_excel(writer, sheet_name='Deaths', index=False)"],"id":"289da777-6d0a-42d1-a801-f5e06663c705","execution_count":null,"outputs":[{"output_type":"stream","text":["Working on the following day: 05-05-2021\n","Working on the following day: 06-05-2021\n","Working on the following day: 07-05-2021\n","Working on the following day: 08-05-2021\n","Working on the following day: 09-05-2021\n","Working on the following day: 10-05-2021\n","Working on the following day: 11-05-2021\n","Working on the following day: 12-05-2021\n","Working on the following day: 13-05-2021\n","Working on the following day: 14-05-2021\n","Working on the following day: 15-05-2021\n"],"name":"stdout"}]}]}